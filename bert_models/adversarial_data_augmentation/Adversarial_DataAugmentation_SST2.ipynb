{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42445f2d",
   "metadata": {},
   "source": [
    "### Jupyter Notebook to Create Data Augmentations for Adversarial Training "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d9a853",
   "metadata": {},
   "source": [
    "We Plan to create 4 Different Augmented Datasets based on different recipes of making \n",
    "\n",
    "1) EmbeddingAugmenter\n",
    "\n",
    "2) SynonymInsertionAugmenter\n",
    "\n",
    "3) WordNetAugmenter \n",
    "\n",
    "4) BackTranslationAugmenter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2fc6e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import transformers\n",
    "import warnings\n",
    "import time\n",
    "import csv        \n",
    "\n",
    "\n",
    "def get_sst_examples(input_file, test=False, discard_values = 0.5):\n",
    "\n",
    "    train_examples = []\n",
    "    test_examples = []\n",
    "\n",
    "    with open(input_file, 'r') as f:\n",
    "\n",
    "        contents = f.read()\n",
    "        file_as_list = contents.splitlines()\n",
    "        for line in file_as_list[1:]:\n",
    "            \n",
    "            is_dropped = np.random.binomial(1, discard_values, 1)[0]\n",
    "            \n",
    "            if not test and is_dropped == 1:\n",
    "                continue\n",
    "                \n",
    "                \n",
    "            text, label = line.split(\"\\t\") \n",
    "            if test:\n",
    "                test_examples.append((text, label))\n",
    "            else : \n",
    "                train_examples.append((text, label))\n",
    "        f.close()\n",
    "\n",
    "    return train_examples, test_examples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9cec03cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67349"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_examples, _ = get_sst_examples('./../../data/SST-2/train.tsv',test=False,discard_values = 0)\n",
    "\n",
    "len(labeled_examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53c439a",
   "metadata": {},
   "source": [
    "#### Let the new Data Augmentation have the original 60K .\n",
    "#### New 20K data will be created by augmenter in random.\n",
    "#### 2 Variations for 10K Examples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "31a41bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_augmented_examples(input_examples,output_tsv,Augmenter , pct_words_to_swap=0.25 , transformations_per_example = 2):\n",
    "    print(f\"Length of Original Document - {len(input_examples)} \\n\")\n",
    "    \n",
    "    augmented_examples = [] \n",
    "    \n",
    "    print(f\"Initiating Creation of Data Augmentation\\n\")\n",
    "    \n",
    "    rng = np.random.default_rng() \n",
    "    \n",
    "    augmented_indexes = rng.choice(len(input_examples), 20_000, replace=False)\n",
    "    \n",
    "    augmenter = Augmenter(pct_words_to_swap = pct_words_to_swap, transformations_per_example = transformations_per_example)\n",
    "    \n",
    "    for index in augmented_indexes : \n",
    "        \n",
    "        augmented_strings = augmenter.augment(input_examples[index][0])\n",
    "        \n",
    "        augmented_examples += [(x,input_examples[index][1]) for x in augmented_strings]\n",
    "        \n",
    "        if len(augmented_examples) % 10 == 0 : \n",
    "            print(f\"Generated {len(augmented_examples)} out of 20_000 Examples \", end = \"\\r\")\n",
    "    \n",
    "    print(f\"Data Generated , Writing it to Augmented Tab Separated Format {output_tsv} : \")\n",
    "    \n",
    "    with open(output_tsv, 'w', newline='') as f:\n",
    "        writer = csv.writer(f, delimiter='\\t')\n",
    "        \n",
    "        for examples in augmented_examples:\n",
    "            writer.writerow(examples)\n",
    "    \n",
    "    print(f\"All Output Written to {output_tsv}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7015b101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Original Document - 67349 \n",
      "\n",
      "Initiating Creation of Data Augmentation\n",
      "\n",
      "Data Generated , Writing it to Augmented Tab Separated Format easydataaugmented.tsv : \n"
     ]
    }
   ],
   "source": [
    "from textattack.augmentation.recipes import EmbeddingAugmenter,SynonymInsertionAugmenter\n",
    "\n",
    "generate_augmented_examples(labeled_examples,\"easydataaugmented.tsv\",SynonymInsertionAugmenter, pct_words_to_swap=0.2 , transformations_per_example = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6b55b4d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['that adore its characters and communicates something rather glamorous about human nature ', 'that loves its characters and communicates something fairly leggy about human nature ', 'that loves its characters and communicates something rather exquisite about human personages ', 'that loves its characters and communicates something rather resplendent about human personage ', 'that loves its features and communicates something rather fantastic about human nature ']\n",
      "431 ms ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 1 -r 1 \n",
    "# EmbeddingAugmenter \n",
    "\n",
    "# Alter default values if desired\n",
    "\n",
    "augmenter = EmbeddingAugmenter(pct_words_to_swap=0.2, transformations_per_example=5)\n",
    "s = labeled_examples[2][0]# Augment\n",
    "\n",
    "\n",
    "print(augmenter.augment(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c6ccc3e0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'i' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_cell_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtimeit\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m-n 1 -r 1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m# SynonymInsertionAugmenter \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mfrom textattack.augmentation.recipes import SynonymInsertionAugmenter\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m# Alter default values if desired\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43maugmenter = SynonymInsertionAugmenter(pct_words_to_swap=0.2, transformations_per_example=5)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43ms = labeled_examples[i][0]# Augment\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mprint(augmenter.augment(s))\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/climate_change/lib/python3.8/site-packages/IPython/core/interactiveshell.py:2338\u001b[0m, in \u001b[0;36mInteractiveShell.run_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2336\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[1;32m   2337\u001b[0m     args \u001b[38;5;241m=\u001b[39m (magic_arg_s, cell)\n\u001b[0;32m-> 2338\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2339\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/climate_change/lib/python3.8/site-packages/IPython/core/magics/execution.py:1166\u001b[0m, in \u001b[0;36mExecutionMagics.timeit\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1163\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m time_number \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.2\u001b[39m:\n\u001b[1;32m   1164\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m-> 1166\u001b[0m all_runs \u001b[38;5;241m=\u001b[39m \u001b[43mtimer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepeat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrepeat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1167\u001b[0m best \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(all_runs) \u001b[38;5;241m/\u001b[39m number\n\u001b[1;32m   1168\u001b[0m worst \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(all_runs) \u001b[38;5;241m/\u001b[39m number\n",
      "File \u001b[0;32m/usr/lib/python3.8/timeit.py:204\u001b[0m, in \u001b[0;36mTimer.repeat\u001b[0;34m(self, repeat, number)\u001b[0m\n\u001b[1;32m    202\u001b[0m r \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(repeat):\n\u001b[0;32m--> 204\u001b[0m     t \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnumber\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    205\u001b[0m     r\u001b[38;5;241m.\u001b[39mappend(t)\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m r\n",
      "File \u001b[0;32m~/climate_change/lib/python3.8/site-packages/IPython/core/magics/execution.py:156\u001b[0m, in \u001b[0;36mTimer.timeit\u001b[0;34m(self, number)\u001b[0m\n\u001b[1;32m    154\u001b[0m gc\u001b[38;5;241m.\u001b[39mdisable()\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 156\u001b[0m     timing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gcold:\n",
      "File \u001b[0;32m<magic-timeit>:8\u001b[0m, in \u001b[0;36minner\u001b[0;34m(_it, _timer)\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'i' is not defined"
     ]
    }
   ],
   "source": [
    "%%timeit -n 1 -r 1 \n",
    "# SynonymInsertionAugmenter \n",
    "\n",
    "\n",
    "from textattack.augmentation.recipes import SynonymInsertionAugmenter\n",
    "# Alter default values if desired\n",
    "\n",
    "augmenter = SynonymInsertionAugmenter(pct_words_to_swap=0.2, transformations_per_example=5)\n",
    "s = labeled_examples[i][0]# Augment\n",
    "\n",
    "\n",
    "print(augmenter.augment(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bf28f5d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['equal the original and in some room even betters it ', 'equals the original and in some path fifty-fifty betters it ', 'equals the original and in some ways eventide amend it ', 'equals the pilot and in some ways flush betters it ', 'match the original and in some ways even meliorate it ']\n",
      "44.1 ms ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 1 -r 1 \n",
    "# WordNetAugmenter \n",
    "\n",
    "from textattack.augmentation.recipes import WordNetAugmenter\n",
    "# Alter default values if desired\n",
    "\n",
    "augmenter = WordNetAugmenter(pct_words_to_swap=0.2, transformations_per_example=5)\n",
    "s = labeled_examples[i][0]# Augment\n",
    "\n",
    "\n",
    "print(augmenter.augment(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b0cf441d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['And the same, and the same, and the same, and the same, and the same, and the same, and the same, and the same, and the same, and the same, and the same, and the same, and the same, and the same, and the same, and the same, and the same, and the same, and the same, and the same, and the same, and the same, and the same, and the same, and the same, and the same, and the same, and the same, and the same, and the same, and the same, and the same, and the same, and the same, and the same, and the same, and the same, and the same, and the same, and the same, and the same, and the same, and the same, and the same, and the same, and the same, and the same, and the same, and the same, and the same, and the same,', 'equal to the original and somehow amplifies even more', 'equal to the original and, in a similar way,', 'equal to the original and, no doubt, the equivalent', 'equal to the original and, to a certain extent, to the width of the year']\n",
      "1min 19s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 1 -r 1 \n",
    "# BackTranslationAugmenter\n",
    "\n",
    "\n",
    "from textattack.augmentation.recipes import BackTranslationAugmenter\n",
    "# Alter default values if desired\n",
    "\n",
    "augmenter = BackTranslationAugmenter(pct_words_to_swap=0.2, transformations_per_example=5)\n",
    "\n",
    "\n",
    "s = labeled_examples[i][0]# Augment\n",
    "\n",
    "\n",
    "print(augmenter.augment(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "942ab82f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['equals the and in some ways betters it ', 'equate the original and in some ways even bettor it ', 'even the original and in some ways equals betters it ', 'equals the original and in some ways even betters path it ']\n",
      "1.05 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "# %%timeit -n 1 -r 1 \n",
    "# # CheckListAugmenter\n",
    "\n",
    "# from textattack.augmentation.recipes import EasyDataAugmenter\n",
    "# # Alter default values if desired\n",
    "\n",
    "# augmenter = EasyDataAugmenter(pct_words_to_swap=0.2, transformations_per_example=5)\n",
    "# s = labeled_examples[i][0]# Augment\n",
    "\n",
    "\n",
    "# print(augmenter.augment(s))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a00e69",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/what-are-adversarial-examples-in-nlp-f928c574478e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a8fc2780",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['equalQ the original and in some ways even bteters it ', 'equals the original and in some ways evne bAtters it ', 'equals the original and in some ways evne bRtters it ', 'equals the ozriginal and in some ways even better it ', 'equals the riginal and in some ways ven betters it ']\n",
      "23.7 ms ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "# %%timeit -n 1 -r 1 \n",
    "\n",
    "\n",
    "# from textattack.augmentation.recipes import CharSwapAugmenter\n",
    "# # Alter default values if desired\n",
    "\n",
    "# augmenter = CharSwapAugmenter(pct_words_to_swap=0.2, transformations_per_example=5)\n",
    "# s = labeled_examples[i][0]# Augment\n",
    "\n",
    "\n",
    "# print(augmenter.augment(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "58a1685e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['equals original and in some ways even it ', 'equals original and in ways even betters it ', 'equals the original and in some even it ', 'the original and in some ways even betters ', 'the original and in some ways even it ']\n",
      "14.7 ms ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "# %%timeit -n 1 -r 1 \n",
    "# # CheckListAugmenter\n",
    "\n",
    "# from textattack.augmentation.recipes import DeletionAugmenter\n",
    "# # Alter default values if desired\n",
    "\n",
    "# augmenter = DeletionAugmenter(pct_words_to_swap=0.2, transformations_per_example=5)\n",
    "# s = labeled_examples[i][0]# Augment\n",
    "\n",
    "\n",
    "# print(augmenter.augment(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0a700c1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['equals the and original in some ways even betters it ', 'equals the original and in some ways betters even it ', 'equals the original in and some ways even betters it ', 'it the original and in some ways even betters equals ', 'the equals original and in some ways even betters it ']\n"
     ]
    }
   ],
   "source": [
    "# SwapAugmenter\n",
    "\n",
    "from textattack.augmentation.recipes import SwapAugmenter\n",
    "# Alter default values if desired\n",
    "\n",
    "augmenter = SwapAugmenter(pct_words_to_swap=0.2, transformations_per_example=5)\n",
    "s = labeled_examples[i][0]# Augment\n",
    "\n",
    "\n",
    "print(augmenter.augment(s))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1b770cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "\n",
    "\n",
    "import warnings\n",
    "import time\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27c801cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sst2_path = '../../data/SST-2'\n",
    "\n",
    "pre_trained_weights_type = 'distilbert-base-uncased'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d4b414e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sst2_train = pd.read_csv(sst2_path + '/train.tsv', delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5480bbf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(67349, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sst2_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b5044a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hide new secretions from the parental units</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>contains no wit , only labored gags</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>that loves its characters and communicates som...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>remains utterly satisfied to remain the same t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>on the worst revenge-of-the-nerds clichés the ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>that 's far too tragic to merit such superfici...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>demonstrates that the director of such hollywo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>of saucy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>a depressed fifteen-year-old 's suicidal poetry</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>are more deeply thought through than in most `...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  label\n",
       "0       hide new secretions from the parental units       0\n",
       "1               contains no wit , only labored gags       0\n",
       "2  that loves its characters and communicates som...      1\n",
       "3  remains utterly satisfied to remain the same t...      0\n",
       "4  on the worst revenge-of-the-nerds clichés the ...      0\n",
       "5  that 's far too tragic to merit such superfici...      0\n",
       "6  demonstrates that the director of such hollywo...      1\n",
       "7                                          of saucy       1\n",
       "8   a depressed fifteen-year-old 's suicidal poetry       0\n",
       "9  are more deeply thought through than in most `...      1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sst2_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab8f937a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    37569\n",
       "0    29780\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Balance of Binary Classification Data \n",
    "sst2_train['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036e2f1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cef53df7",
   "metadata": {},
   "source": [
    "### Import Model Class , tokenizer Class and Pretrained Weights for Fine Tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b1aeca2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertModel , DistilBertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "76fdcdc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8aec62336064e34898ac47cb2b560fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/483 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "612158c999e14e09abcc0398bfc941ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/256M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.weight', 'vocab_transform.weight', 'vocab_layer_norm.bias', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e9708a71e094bfb888e3fc23740afeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "071cff7bd0fd401982c90a4735e2eb7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbf1cc2699c7424cb0b44f923d544523",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/455k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Setting pre_trained weights \n",
    "\n",
    "pre_trained_weights = pre_trained_weights_type \n",
    "\n",
    "# Call the Model \n",
    "distilbert_model = DistilBertModel.from_pretrained(pre_trained_weights)\n",
    "\n",
    "# Call the Tokenizer \n",
    "\n",
    "distilbert_tokenizer = DistilBertTokenizer.from_pretrained(pre_trained_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef66342",
   "metadata": {},
   "source": [
    "### https://huggingface.co/docs/transformers/training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c29d1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178227e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c000e0e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a891f47a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c0e3ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "573614e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries needed\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "78ede3e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU\n"
     ]
    }
   ],
   "source": [
    "#Get the GPU device if it exists, load the SST-2 dataset, and create PyTorch datasets and dataloaders for the training and validation sets\n",
    "GPU  = get_gpu()\n",
    "\n",
    "def get_sst_examples(input_file, test=False):\n",
    "\n",
    "    train_examples = []\n",
    "    test_examples = []\n",
    "\n",
    "    with open(input_file, 'r') as f:\n",
    "\n",
    "        contents = f.read()\n",
    "        file_as_list = contents.splitlines()\n",
    "        for line in file_as_list[1:]:\n",
    "            \n",
    "            # random drop 90% of examples for checking\n",
    "            is_dropped = np.random.binomial(1, 0.6, 1)[0]\n",
    "            \n",
    "            if not test and is_dropped == 1:\n",
    "                continue\n",
    "                \n",
    "                \n",
    "            text, label = line.split(\"\\t\") \n",
    "            if test:\n",
    "                test_examples.append((text, label))\n",
    "            else : \n",
    "                train_examples.append((text, label))\n",
    "        f.close()\n",
    "\n",
    "    return train_examples, test_examples\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "309392c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_examples, _ = get_sst_examples('./../../data/SST-2/train.tsv')\n",
    "_, test_examples = get_sst_examples('./../../data/SST-2/dev.tsv', test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "13f25e6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('remains utterly satisfied to remain the same throughout ', '0')"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_examples[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "cc9740f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data_loader(input_examples, label_map,batch_size=64, do_shuffle = False, balance_label_examples = False):\n",
    "    '''\n",
    "    Generate a Dataloader given the input examples, eventually masked if they are \n",
    "    to be considered NOT labeled.\n",
    "    '''\n",
    "\n",
    "    #-----------------------------------------------\n",
    "    # Generate input examples to the Transformer\n",
    "    #-----------------------------------------------\n",
    "    input_ids = []\n",
    "    input_mask_array = []\n",
    "    label_id_array = []\n",
    "\n",
    "    # Tokenization \n",
    "    for text in input_examples:\n",
    "        # each sentence is tokenized and converted into an ID from the vocabulary\n",
    "        \n",
    "        encoded_sent = tokenizer.encode(text[0], add_special_tokens=True, max_length=64, padding=\"max_length\", truncation=True)\n",
    "        \n",
    "        input_ids.append(encoded_sent)\n",
    "        \n",
    "        label_id_array.append(label_map[text[1]])\n",
    "         \n",
    "    # input_ids ---> contains a list of list of all word embeddings for the sentence \n",
    "    # label_id_array ---> contains a list of actual labels which can be (0, 1, 'UNK')\n",
    "  \n",
    "    # Attention to token (to ignore padded input wordpieces)\n",
    "    for sent in input_ids:\n",
    "        att_mask = [int(token_id > 0) for token_id in sent]                          \n",
    "        input_mask_array.append(att_mask)\n",
    "    # Convertion to Tensor\n",
    "    \n",
    "    \n",
    "    input_ids = torch.tensor(input_ids) \n",
    "    input_mask_array = torch.tensor(input_mask_array)\n",
    "    label_id_array = torch.tensor(label_id_array, dtype=torch.long)\n",
    "    \n",
    "    # Building the TensorDataset\n",
    "    dataset = TensorDataset(input_ids, input_mask_array, label_id_array)\n",
    "    \n",
    "    if do_shuffle:\n",
    "        sampler = RandomSampler\n",
    "    else:\n",
    "        sampler = SequentialSampler\n",
    "\n",
    "    # Building the DataLoader\n",
    "    return DataLoader(\n",
    "                dataset,  # The training samples.\n",
    "                sampler = sampler(dataset), \n",
    "                batch_size = batch_size) # Trains with this batch size.\n",
    "\n",
    "\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "348ddd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {'0': 0, '1': 1}\n",
    "train_examples = labeled_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "07406f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = generate_data_loader(train_examples, label_map,batch_size =64, do_shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "38faba8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_dataloader = generate_data_loader(test_examples, label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "926a50ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Name: \t\tget_gpu\n",
    "#Purpose: \tchecks if a GPU device is avaliable\n",
    "#Input: \tnone\n",
    "#Output: \tGPU -> GPU device if applicable, none if not\n",
    "def  get_gpu():\n",
    "    #Check if a GPU is avaliable and if so return it\n",
    "    GPU  =  None\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"Using GPU\")\n",
    "        GPU  = torch.device(\"cuda\")\n",
    "    else:\n",
    "        print(\"No GPU device avaliable! Using CPU\")\n",
    "    return  GPU\n",
    "\n",
    "#Name: \t\ttransfer_device\n",
    "#Purpose: \ttransfers model / data to the GPU devie if present\n",
    "#Inputs: \tGPU -> GPU device if applicable, none if not\n",
    "# \t\t \tdata -> data to transfer\n",
    "#Output: \tdata -> data that has been transferred if applicable\n",
    "def  transfer_device(GPU, data):\n",
    "    if(GPU  !=  None):\n",
    "        data = data.to(GPU)\n",
    "    return data\n",
    "\n",
    "#Name: \t\tcount_correct\n",
    "#Purpose: \tcount the number of correct model predictions in a batch\n",
    "#Inputs: \tpredictions -> model predictions\n",
    "#\t\t \ttargets -> target labels\n",
    "#Outputs: \tcorrect -> number of correct model predictions\n",
    "def  count_correct(predictions, targets):\n",
    "\t#Create variables to store the number of correct predictions along with the index of the prediction in the batch\n",
    "    correct =  0\n",
    "    index =  0\n",
    "  \n",
    "\t#Loop across all predictions in the batch and count the number correct\n",
    "    while(index <  len(predictions)):\n",
    "        #Convert the prediction and target to lists\n",
    "        prediction =  list(predictions[index])\n",
    "        target =  list(targets[index])\n",
    "\n",
    "        #Get the max index indicating the truth value from the prediction and target\n",
    "        prediction_index = prediction.index(max(prediction))\n",
    "        target_index = target.index(max(target))\n",
    "\n",
    "        #If the max indices are the same increment correct\n",
    "        if(prediction_index == target_index):\n",
    "            correct +=  1\n",
    "        index +=  1\n",
    "    return correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "70b4fd1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "85d9e20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def  binary_cross_entropy(predictions, targets):\n",
    "    loss =  -(targets * torch.log(predictions) + (1  - targets) * torch.log(1  - predictions))\n",
    "    loss = torch.mean(loss)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f9ebe59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F \n",
    "\n",
    "#Name: \t\ttrain_model\n",
    "#Purpose: \ttrain the model while evaluating its performance\n",
    "#Inputs: \tGPU -> GPU device to train / evaluate on\n",
    "# \t\t\ttrain_dataloader -> training set dataloader\n",
    "# \t\t\tdev_dataloader -> development set dataloader\n",
    "# \t\t\ttokenizer -> text tokenizer for model\n",
    "# \t\t\tmodel -> model to train / evaluate\n",
    "# \t\t\toptimizer -> optimizer to use to update model parameters\n",
    "# \t\t\tcriterion -> criterion to use to compute loss values\n",
    "#Outputs: \tmodel -> model after training\n",
    "\n",
    "def  train_model(GPU, train_dataloader, dev_dataloader, tokenizer, model, optimizer, criterion,epochs):\n",
    "    #Evaluate the performance of the model before training\n",
    "    valid_loss, valid_accuracy = evaluate(GPU, dev_dataloader, tokenizer, model, criterion)\n",
    "    print(\"Pre-training validation loss: \"+str(valid_loss)+\" --- Accuracy: \"+str(valid_accuracy))\n",
    "    print()\n",
    "\n",
    "    #Train the model across 3 epochs and evaluate its performance\n",
    "    for epoch in  range(epochs):\n",
    "        model, train_loss, train_accuracy = train(GPU, train_dataloader, tokenizer, model, optimizer, criterion)\n",
    "        valid_loss, valid_accuracy = evaluate(GPU, dev_dataloader, tokenizer, model, criterion)\n",
    "\n",
    "        #Print performance stats\n",
    "        print(\" \", end=\"\\r\")\n",
    "        print(\"Epoch: \"+str(epoch+1))\n",
    "        print(\"Training loss: \"+str(train_loss)+\" --- Accuracy: \"+str(train_accuracy))\n",
    "        print(\"Validation loss: \"+str(valid_loss)+\" --- Accuracy: \"+str(valid_accuracy))\n",
    "        print()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "84ad79c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def  train(GPU, dataloader, tokenizer, model, optimizer, criterion):\n",
    "    #Place the network in training mode, create a variable to store the total loss, and create a variable to store the total number of correct predictions\n",
    "    model.train()\n",
    "    total_loss =  0\n",
    "    total_correct =  0\n",
    "\n",
    "    #Loop through all batches in the dataloader\n",
    "    for batch_number, (texts, labels) in  enumerate(dataloader):\n",
    "        #Tokenize the text segments, get the model predictions, compute the loss, and add the loss to the total loss\n",
    "        tokenized_segments = tokenizer(texts, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "        tokenized_segments_input_ids, tokenized_segments_attention_mask = tokenized_segments.input_ids, tokenized_segments.attention_mask\n",
    "        model_predictions = F.softmax(model(input_ids=transfer_device(GPU, tokenized_segments_input_ids), attention_mask=transfer_device(GPU, tokenized_segments_attention_mask))['logits'], dim=1)\n",
    "        loss = criterion(model_predictions, transfer_device(GPU, labels))\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        #Count the number of correct predictions by the model in the batch and add this to the total correct\n",
    "        correct = count_correct(model_predictions.cpu().detach().numpy(), labels.numpy())\n",
    "        total_correct += correct\n",
    "\n",
    "        #Zero the optimizer, compute the gradients, and update the model parameters\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(\"Training batch index: \"+str(batch_number)+\"/\"+str(len(dataloader))+  \" ( \"+str(batch_number/len(dataloader)*100)+\"% )\", end='\\r')\n",
    "\n",
    "    #Compute the average loss and accuracy across the epoch\n",
    "    average_loss = total_loss /  len(dataloader)\n",
    "    accuracy = total_correct / dataloader.dataset.__len__()\n",
    "    return model, average_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f4c73ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def  evaluate(GPU, dataloader, tokenizer, model, criterion):\n",
    "    #Place the network in evaluation mode, create a variable to store the total loss, and create a variable to store the total number of correct predictions\n",
    "    model.eval()\n",
    "    total_loss =  0\n",
    "    total_correct =  0\n",
    "\n",
    "    #Loop through all batches in the dataloader\n",
    "    for batch_number,(input_ids, input_mask_array, label_id_array) in  enumerate(dataloader):\n",
    "        #Tokenize the text segments, get the model predictions, compute the loss, and add the loss to the total loss\n",
    "        tokenized_segments = tokenizer(texts, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "        tokenized_segments_input_ids, tokenized_segments_attention_mask = tokenized_segments.input_ids, tokenized_segments.attention_mask\n",
    "        model_predictions = F.softmax(model(input_ids=transfer_device(GPU, tokenized_segments_input_ids), attention_mask=transfer_device(GPU, tokenized_segments_attention_mask))['logits'], dim=1)\n",
    "        loss = criterion(model_predictions, transfer_device(GPU, labels))\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        #Count the number of correct predictions by the model in the batch and add this to the total correct\n",
    "        correct = count_correct(model_predictions.cpu().detach().numpy(), labels.numpy())\n",
    "        total_correct += correct\n",
    "        print(\"Evaluation batch index: \"+str(batch_number)+\"/\"+str(len(dataloader))+  \" ( \"+str(batch_number/len(dataloader)*100)+\"% )\", end='\\r')\n",
    "\n",
    "    #Compute the average loss and accuracy across the epoch\n",
    "    average_loss = total_loss /  len(dataloader)\n",
    "    accuracy = total_correct / dataloader.dataset.__len__()\n",
    "    return average_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "338cac63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AdamW\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4ede8285",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "type"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SST_Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6fc21bbb",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n"
     ]
    }
   ],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=32, shuffle=False, num_workers=4)\n",
    "\n",
    "\n",
    "for batch_number, (texts, labels) in enumerate(train_dataloader): \n",
    "    print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "29c410be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-cased were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.weight', 'vocab_transform.weight', 'vocab_layer_norm.bias', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-cased and are newly initialized: ['classifier.weight', 'pre_classifier.weight', 'pre_classifier.bias', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "#Create the tokenizer, model, optimizer, and criterion\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-cased')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = transfer_device(GPU, DistilBertForSequenceClassification.from_pretrained('distilbert-base-cased'))\n",
    "\n",
    "\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "criterion = binary_cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bf4effe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-training validation loss: 0.6919103366988045 --- Accuracy: 0.5068119891008175\n",
      "\n",
      "Epoch: 1on batch index: 34/35 ( 97.14285714285714% ))\n",
      "Training loss: 0.4591036279884617 --- Accuracy: 0.78125\n",
      "Validation loss: 0.3870589298861367 --- Accuracy: 0.8256130790190735\n",
      "\n",
      "Epoch: 2on batch index: 34/35 ( 97.14285714285714% ))\n",
      "Training loss: 0.2944409636857358 --- Accuracy: 0.8788623595505618\n",
      "Validation loss: 0.3795064274753843 --- Accuracy: 0.8374205267938238\n",
      "\n",
      "Epoch: 3on batch index: 34/35 ( 97.14285714285714% ))\n",
      "Training loss: 0.16472508001388905 --- Accuracy: 0.9419475655430711\n",
      "Validation loss: 0.5044310918876103 --- Accuracy: 0.8292461398728429\n",
      "\n",
      "Epoch: 4on batch index: 34/35 ( 97.14285714285714% ))\n",
      "Training loss: 0.08229120714896906 --- Accuracy: 0.9736657303370787\n",
      "Validation loss: 0.5399618868316923 --- Accuracy: 0.8346957311534968\n",
      "\n",
      "Epoch: 5on batch index: 34/35 ( 97.14285714285714% ))\n",
      "Training loss: 0.05374773938125104 --- Accuracy: 0.9836142322097379\n",
      "Validation loss: 0.6238758955683027 --- Accuracy: 0.8374205267938238\n",
      "\n",
      "Epoch: 6on batch index: 34/35 ( 97.14285714285714% ))\n",
      "Training loss: 0.032946428632422975 --- Accuracy: 0.989934456928839\n",
      "Validation loss: 0.7314419902861118 --- Accuracy: 0.8346957311534968\n",
      "\n",
      "Epoch: 7on batch index: 34/35 ( 97.14285714285714% ))\n",
      "Training loss: 0.03485832899444377 --- Accuracy: 0.9886470037453183\n",
      "Validation loss: 0.7282179798398699 --- Accuracy: 0.821071752951862\n",
      "\n",
      "Epoch: 8on batch index: 34/35 ( 97.14285714285714% ))\n",
      "Training loss: 0.02376954013779097 --- Accuracy: 0.9913389513108615\n",
      "Validation loss: 0.7527049094438553 --- Accuracy: 0.8337874659400545\n",
      "\n",
      "Epoch: 9on batch index: 34/35 ( 97.14285714285714% ))\n",
      "Training loss: 0.019520468527428485 --- Accuracy: 0.9941479400749064\n",
      "Validation loss: 0.8630015228475844 --- Accuracy: 0.8256130790190735\n",
      "\n",
      "Epoch: 10n batch index: 34/35 ( 97.14285714285714% ))\n",
      "Training loss: 0.017561733954645387 --- Accuracy: 0.994499063670412\n",
      "Validation loss: 0.8498672894069127 --- Accuracy: 0.8237965485921889\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Train and save the model\n",
    "model = train_model(GPU, train_dataloader, valid_dataloader, tokenizer, model, optimizer, criterion,epochs =10 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0562f3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "    'tokenizer': tokenizer,\n",
    "    'model_state_dict': model.state_dict()},\n",
    "    model+\".pt\")\n",
    "return"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

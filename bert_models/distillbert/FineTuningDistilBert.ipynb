{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1b770cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "\n",
    "\n",
    "import warnings\n",
    "import time\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "573614e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries needed\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78ede3e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU device avaliable! Using CPU\n"
     ]
    }
   ],
   "source": [
    "#Get the GPU device if it exists, load the SST-2 dataset, and create PyTorch datasets and dataloaders for the training and validation sets\n",
    "def  get_gpu():\n",
    "    #Check if a GPU is avaliable and if so return it\n",
    "    GPU  =  None\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"Using GPU\")\n",
    "        GPU  = torch.device(\"cuda\")\n",
    "    else:\n",
    "        print(\"No GPU device avaliable! Using CPU\")\n",
    "    return  GPU\n",
    "\n",
    "GPU  = get_gpu()\n",
    "\n",
    "def get_sst_examples(input_file, test=False):\n",
    "\n",
    "    train_examples = []\n",
    "    test_examples = []\n",
    "\n",
    "    with open(input_file, 'r') as f:\n",
    "\n",
    "        contents = f.read()\n",
    "        file_as_list = contents.splitlines()\n",
    "        for line in file_as_list[1:]:\n",
    "            \n",
    "            # random drop 90% of examples for checking\n",
    "            is_dropped = np.random.binomial(1, 0.6, 1)[0]\n",
    "            \n",
    "            if not test and is_dropped == 1:\n",
    "                continue\n",
    "                \n",
    "                \n",
    "            text, label = line.split(\"\\t\") \n",
    "            if test:\n",
    "                test_examples.append((text, label))\n",
    "            else : \n",
    "                train_examples.append((text, label))\n",
    "        f.close()\n",
    "\n",
    "    return train_examples, test_examples\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "309392c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_examples, _ = get_sst_examples('./../../data/SST-2/train.tsv')\n",
    "_, test_examples = get_sst_examples('./../../data/SST-2/dev.tsv', test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13f25e6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('hide new secretions from the parental units ', '0')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_examples[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc9740f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data_loader(input_examples, label_map,tokenizer,batch_size=64, do_shuffle = False, balance_label_examples = False):\n",
    "    '''\n",
    "    Generate a Dataloader given the input examples, eventually masked if they are \n",
    "    to be considered NOT labeled.\n",
    "    '''\n",
    "\n",
    "    #-----------------------------------------------\n",
    "    # Generate input examples to the Transformer\n",
    "    #-----------------------------------------------\n",
    "    input_ids = []\n",
    "    input_mask_array = []\n",
    "    label_id_array = []\n",
    "\n",
    "    # Tokenization \n",
    "    for text in input_examples:\n",
    "        # each sentence is tokenized and converted into an ID from the vocabulary\n",
    "        \n",
    "        encoded_sent = tokenizer.encode(text[0], add_special_tokens=True, max_length=64, padding=\"max_length\", truncation=True)\n",
    "        \n",
    "        input_ids.append(encoded_sent)\n",
    "        label = [0]*2\n",
    "        label[label_map[text[1]]] =  1\n",
    "        label_id_array.append(label)\n",
    "        \n",
    "    # input_ids ---> contains a list of list of all word embeddings for the sentence \n",
    "    # label_id_array ---> contains a list of actual labels which can be (0, 1, 'UNK')\n",
    "  \n",
    "    # Attention to token (to ignore padded input wordpieces)\n",
    "    for sent in input_ids:\n",
    "        att_mask = [int(token_id > 0) for token_id in sent]                          \n",
    "        input_mask_array.append(att_mask)\n",
    "    # Convertion to Tensor\n",
    "    \n",
    "    input_ids = torch.tensor(input_ids) \n",
    "    input_mask_array = torch.tensor(input_mask_array)\n",
    "    label_id_array = torch.tensor(label_id_array)# , dtype=torch.long)\n",
    "    # Building the TensorDataset\n",
    "    dataset = TensorDataset(input_ids, input_mask_array, label_id_array)\n",
    "    \n",
    "    if do_shuffle:\n",
    "        sampler = RandomSampler\n",
    "    else:\n",
    "        sampler = SequentialSampler\n",
    "\n",
    "    # Building the DataLoader\n",
    "    return DataLoader(\n",
    "                dataset,  # The training samples.\n",
    "                sampler = sampler(dataset), \n",
    "                batch_size = batch_size) # Trains with this batch size.\n",
    "\n",
    "\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "348ddd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {'0': 0, '1': 1}\n",
    "train_examples = labeled_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "926a50ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def  get_gpu():\n",
    "    #Check if a GPU is avaliable and if so return it\n",
    "    GPU  =  None\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"Using GPU\")\n",
    "        GPU  = torch.device(\"cuda\")\n",
    "    else:\n",
    "        print(\"No GPU device avaliable! Using CPU\")\n",
    "    return  GPU\n",
    "\n",
    "#Name: \t\ttransfer_device\n",
    "#Purpose: \ttransfers model / data to the GPU devie if present\n",
    "#Inputs: \tGPU -> GPU device if applicable, none if not\n",
    "# \t\t \tdata -> data to transfer\n",
    "#Output: \tdata -> data that has been transferred if applicable\n",
    "def  transfer_device(GPU, data):\n",
    "    if(GPU  !=  None):\n",
    "        data = data.to(GPU)\n",
    "    return data\n",
    "\n",
    "#Name: \t\tcount_correct\n",
    "#Purpose: \tcount the number of correct model predictions in a batch\n",
    "#Inputs: \tpredictions -> model predictions\n",
    "#\t\t \ttargets -> target labels\n",
    "#Outputs: \tcorrect -> number of correct model predictions\n",
    "def  count_correct(predictions, targets):\n",
    "\t#Create variables to store the number of correct predictions along with the index of the prediction in the batch\n",
    "    correct =  0\n",
    "    index =  0\n",
    "  \n",
    "\t#Loop across all predictions in the batch and count the number correct\n",
    "    while(index <  len(predictions)):\n",
    "        #Convert the prediction and target to lists\n",
    "        prediction =  list(predictions[index])\n",
    "        target =  list(targets[index])\n",
    "\n",
    "        #Get the max index indicating the truth value from the prediction and target\n",
    "        prediction_index = prediction.index(max(prediction))\n",
    "        target_index = target.index(max(target))\n",
    "\n",
    "        #If the max indices are the same increment correct\n",
    "        if(prediction_index == target_index):\n",
    "            correct +=  1\n",
    "        index +=  1\n",
    "    return correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70b4fd1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU device avaliable! Using CPU\n"
     ]
    }
   ],
   "source": [
    "get_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "85d9e20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_cross_entropy(predictions, targets):\n",
    "    loss =  -(targets * torch.log(predictions) + (1  - targets) * torch.log(1  - predictions))\n",
    "    \n",
    "    loss = torch.mean(loss)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f9ebe59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F \n",
    "\n",
    "#Name: \t\ttrain_model\n",
    "#Purpose: \ttrain the model while evaluating its performance\n",
    "#Inputs: \tGPU -> GPU device to train / evaluate on\n",
    "# \t\t\ttrain_dataloader -> training set dataloader\n",
    "# \t\t\tdev_dataloader -> development set dataloader\n",
    "# \t\t\ttokenizer -> text tokenizer for model\n",
    "# \t\t\tmodel -> model to train / evaluate\n",
    "# \t\t\toptimizer -> optimizer to use to update model parameters\n",
    "# \t\t\tcriterion -> criterion to use to compute loss values\n",
    "#Outputs: \tmodel -> model after training\n",
    "\n",
    "def  train_model(GPU, train_dataloader, dev_dataloader, tokenizer, model, optimizer, criterion,epochs):\n",
    "    #Evaluate the performance of the model before training\n",
    "    \n",
    "    valid_loss, valid_accuracy = evaluate(GPU, dev_dataloader, model, criterion)\n",
    "    print(\"Pre-training validation loss: \"+str(valid_loss)+\" --- Accuracy: \"+str(valid_accuracy))\n",
    "    print()\n",
    "\n",
    "    #Train the model across 3 epochs and evaluate its performance\n",
    "    for epoch in  range(epochs):\n",
    "        model, train_loss, train_accuracy = train(GPU, train_dataloader, model, optimizer, criterion)\n",
    "        valid_loss, valid_accuracy = evaluate(GPU, dev_dataloader, model, criterion)\n",
    "\n",
    "        #Print performance stats\n",
    "        print(\" \", end=\"\\r\")\n",
    "        print(\"Epoch: \"+str(epoch+1))\n",
    "        print(\"Training loss: \"+str(train_loss)+\" --- Accuracy: \"+str(train_accuracy))\n",
    "        print(\"Validation loss: \"+str(valid_loss)+\" --- Accuracy: \"+str(valid_accuracy))\n",
    "        print()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "84ad79c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def  train(GPU, dataloader, model, optimizer, criterion):\n",
    "    #Place the network in training mode, create a variable to store the total loss, and create a variable to store the total number of correct predictions\n",
    "    model.train()\n",
    "    total_loss =  0\n",
    "    total_correct =  0\n",
    "\n",
    "    #Loop through all batches in the dataloader\n",
    "    for batch_number,(input_ids, input_mask_array, labels)  in  enumerate(dataloader):\n",
    "        #Tokenize the text segments, get the model predictions, compute the loss, and add the loss to the total loss\n",
    "        model_predictions = F.softmax(model(input_ids=transfer_device(GPU, input_ids), attention_mask=transfer_device(GPU, input_mask_array))['logits'], dim=1)\n",
    "\n",
    "        loss = criterion(model_predictions, transfer_device(GPU, labels))\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "\n",
    "        #Count the number of correct predictions by the model in the batch and add this to the total correct\n",
    "        correct = count_correct(model_predictions.cpu().detach().numpy(), labels.numpy())\n",
    "        total_correct += correct\n",
    "\n",
    "        #Zero the optimizer, compute the gradients, and update the model parameters\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(\"Training batch index: \"+str(batch_number)+\"/\"+str(len(dataloader))+  \" ( \"+str(batch_number/len(dataloader)*100)+\"% )\", end='\\r')\n",
    "\n",
    "    #Compute the average loss and accuracy across the epoch\n",
    "    average_loss = total_loss /  len(dataloader)\n",
    "    accuracy = total_correct / dataloader.dataset.__len__()\n",
    "    return model, average_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f4c73ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def  evaluate(GPU, dataloader, model, criterion):\n",
    "    #Place the network in evaluation mode, create a variable to store the total loss, and create a variable to store the total number of correct predictions\n",
    "    model.eval()\n",
    "    total_loss =  0\n",
    "    total_correct =  0\n",
    "\n",
    "    #Loop through all batches in the dataloader\n",
    "    for batch_number,(input_ids, input_mask_array, labels) in  enumerate(dataloader):\n",
    "        #Tokenize the text segments, get the model predictions, compute the loss, and add the loss to the total loss\n",
    "\n",
    "        model_predictions = F.softmax(model(input_ids=transfer_device(GPU, input_ids), attention_mask=transfer_device(GPU, input_mask_array))['logits'], dim=1)\n",
    "        \n",
    "        loss = criterion(model_predictions, transfer_device(GPU, labels))\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "\n",
    "        #Count the number of correct predictions by the model in the batch and add this to the total correct\n",
    "        correct = count_correct(model_predictions.cpu().detach().numpy(), labels.numpy())\n",
    "        total_correct += correct\n",
    "        print(\"Evaluation batch index: \"+str(batch_number)+\"/\"+str(len(dataloader))+  \" ( \"+str(batch_number/len(dataloader)*100)+\"% )\", end='\\r')\n",
    "\n",
    "    #Compute the average loss and accuracy across the epoch\n",
    "    average_loss = total_loss /  len(dataloader)\n",
    "    accuracy = total_correct / dataloader.dataset.__len__()\n",
    "    return average_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "338cac63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AdamW\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4ede8285",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "transformer_type = 'distilbert-base-cased'\n",
    "\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(transformer_type)\n",
    "\n",
    "train_dataloader = generate_data_loader(train_examples, label_map,tokenizer,batch_size =64, do_shuffle = True)\n",
    "\n",
    "test_dataloader = generate_data_loader(test_examples, label_map,tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7f9db8c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-cased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-cased and are newly initialized: ['pre_classifier.bias', 'classifier.weight', 'classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "#Create the tokenizer, model, optimizer, and criterion\n",
    "model = transfer_device(GPU, DistilBertForSequenceClassification.from_pretrained(transformer_type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "29c410be",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "criterion = binary_cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bf4effe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-training validation loss: 0.6947114552770343 --- Accuracy: 0.4908256880733945\n",
      "\n",
      "Training batch index: 14/422 ( 3.3175355450236967% )\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [40]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#Train and save the model\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mGPU\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [21]\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(GPU, train_dataloader, dev_dataloader, tokenizer, model, optimizer, criterion, epochs)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m#Train the model across 3 epochs and evaluate its performance\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m  \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m---> 23\u001b[0m     model, train_loss, train_accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mGPU\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m     valid_loss, valid_accuracy \u001b[38;5;241m=\u001b[39m evaluate(GPU, dev_dataloader, model, criterion)\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;66;03m#Print performance stats\u001b[39;00m\n",
      "Input \u001b[0;32mIn [35]\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(GPU, dataloader, model, optimizer, criterion)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m#Loop through all batches in the dataloader\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_number,(input_ids, input_mask_array, labels)  \u001b[38;5;129;01min\u001b[39;00m  \u001b[38;5;28menumerate\u001b[39m(dataloader):\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;66;03m#Tokenize the text segments, get the model predictions, compute the loss, and add the loss to the total loss\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m     model_predictions \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39msoftmax(\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransfer_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mGPU\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransfer_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mGPU\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_mask_array\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlogits\u001b[39m\u001b[38;5;124m'\u001b[39m], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     12\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(model_predictions, transfer_device(GPU, labels))\n\u001b[1;32m     14\u001b[0m     total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/ADL/lib/python3.8/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/ADL/lib/python3.8/site-packages/transformers/models/distilbert/modeling_distilbert.py:727\u001b[0m, in \u001b[0;36mDistilBertForSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    719\u001b[0m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    720\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[1;32m    721\u001b[0m \u001b[38;5;124;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[1;32m    722\u001b[0m \u001b[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[1;32m    723\u001b[0m \u001b[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[1;32m    724\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    725\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m--> 727\u001b[0m distilbert_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistilbert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    728\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    729\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    730\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    731\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    732\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    733\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    734\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    735\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    736\u001b[0m hidden_state \u001b[38;5;241m=\u001b[39m distilbert_output[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# (bs, seq_len, dim)\u001b[39;00m\n\u001b[1;32m    737\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m hidden_state[:, \u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# (bs, dim)\u001b[39;00m\n",
      "File \u001b[0;32m~/ADL/lib/python3.8/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/ADL/lib/python3.8/site-packages/transformers/models/distilbert/modeling_distilbert.py:549\u001b[0m, in \u001b[0;36mDistilBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    547\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inputs_embeds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    548\u001b[0m     inputs_embeds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(input_ids)  \u001b[38;5;66;03m# (bs, seq_length, dim)\u001b[39;00m\n\u001b[0;32m--> 549\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    550\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    551\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    552\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    553\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    554\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    555\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    556\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ADL/lib/python3.8/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/ADL/lib/python3.8/site-packages/transformers/models/distilbert/modeling_distilbert.py:327\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[0;34m(self, x, attn_mask, head_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    324\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states:\n\u001b[1;32m    325\u001b[0m     all_hidden_states \u001b[38;5;241m=\u001b[39m all_hidden_states \u001b[38;5;241m+\u001b[39m (hidden_state,)\n\u001b[0;32m--> 327\u001b[0m layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    328\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\n\u001b[1;32m    329\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    330\u001b[0m hidden_state \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "File \u001b[0;32m~/ADL/lib/python3.8/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/ADL/lib/python3.8/site-packages/transformers/models/distilbert/modeling_distilbert.py:271\u001b[0m, in \u001b[0;36mTransformerBlock.forward\u001b[0;34m(self, x, attn_mask, head_mask, output_attentions)\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;124;03mParameters:\u001b[39;00m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;124;03m    x: torch.tensor(bs, seq_length, dim)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;124;03m    torch.tensor(bs, seq_length, dim) The output of the transformer block contextualization.\u001b[39;00m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    270\u001b[0m \u001b[38;5;66;03m# Self-Attention\u001b[39;00m\n\u001b[0;32m--> 271\u001b[0m sa_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    276\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n\u001b[1;32m    280\u001b[0m     sa_output, sa_weights \u001b[38;5;241m=\u001b[39m sa_output  \u001b[38;5;66;03m# (bs, seq_length, dim), (bs, n_heads, seq_length, seq_length)\u001b[39;00m\n",
      "File \u001b[0;32m~/ADL/lib/python3.8/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/ADL/lib/python3.8/site-packages/transformers/models/distilbert/modeling_distilbert.py:217\u001b[0m, in \u001b[0;36mMultiHeadSelfAttention.forward\u001b[0;34m(self, query, key, value, mask, head_mask, output_attentions)\u001b[0m\n\u001b[1;32m    214\u001b[0m     weights \u001b[38;5;241m=\u001b[39m weights \u001b[38;5;241m*\u001b[39m head_mask\n\u001b[1;32m    216\u001b[0m context \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmatmul(weights, v)  \u001b[38;5;66;03m# (bs, n_heads, q_length, dim_per_head)\u001b[39;00m\n\u001b[0;32m--> 217\u001b[0m context \u001b[38;5;241m=\u001b[39m \u001b[43munshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# (bs, q_length, dim)\u001b[39;00m\n\u001b[1;32m    218\u001b[0m context \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout_lin(context)  \u001b[38;5;66;03m# (bs, q_length, dim)\u001b[39;00m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "File \u001b[0;32m~/ADL/lib/python3.8/site-packages/transformers/models/distilbert/modeling_distilbert.py:198\u001b[0m, in \u001b[0;36mMultiHeadSelfAttention.forward.<locals>.unshape\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21munshape\u001b[39m(x):\n\u001b[1;32m    197\u001b[0m     \u001b[38;5;124;03m\"\"\"group heads\"\"\"\u001b[39;00m\n\u001b[0;32m--> 198\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontiguous\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mview(bs, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_heads \u001b[38;5;241m*\u001b[39m dim_per_head)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Train and save the model\n",
    "\n",
    "\n",
    "\n",
    "model = train_model(GPU, train_dataloader, test_dataloader, tokenizer, model, optimizer, criterion,epochs =10 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0562f3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "    'tokenizer': tokenizer,\n",
    "    'model_state_dict': model.state_dict()},\n",
    "    model+\".pt\")\n",
    "return"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
